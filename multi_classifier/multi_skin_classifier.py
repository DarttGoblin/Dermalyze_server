# -*- coding: utf-8 -*-
"""multi_skin_classifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dr37I96U0kkEIZnY-ctUqqlc4Ae7AdH_
"""

import os
import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, Model
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.applications import EfficientNetV2B0
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
from sklearn.model_selection import train_test_split

# Configs
IMG_SIZE = (224, 224)
BATCH_SIZE = 32
EPOCHS = 10
DATA_DIR = '/content/drive/MyDrive/multiclass_data'
CSV_PATH = '/content/drive/MyDrive/multiclass_data/HAM10000_metadata.csv'

# Load metadata
df = pd.read_csv(CSV_PATH)

# Get class labels
class_names = os.listdir(DATA_DIR)
class_names = sorted([cls for cls in class_names if os.path.isdir(os.path.join(DATA_DIR, cls))])
class_to_idx = {cls: i for i, cls in enumerate(class_names)}

# Filter metadata to include only images in multiclass_data
valid_files = []
for cls in class_names:
    valid_files += [f for f in os.listdir(os.path.join(DATA_DIR, cls)) if f.endswith('.jpg')]
valid_ids = [f[:-4] for f in valid_files]
df = df[df['image_id'].isin(valid_ids)].copy()

# Assign label indices
df['label'] = df['dx'].map(class_to_idx)

# Encode metadata
df['sex'] = LabelEncoder().fit_transform(df['sex'].fillna('unknown'))
df['age'] = df['age'].fillna(df['age'].mean()) / 100.0  # Normalize
loc_encoded = OneHotEncoder(sparse_output=False).fit_transform(df['localization'].fillna('unknown').values.reshape(-1, 1))
df['localization'] = loc_encoded.tolist()

# Load data
def load_data(df):
    images, ages, sexes, locs, labels = [], [], [], [], []
    for _, row in df.iterrows():
        cls = row['dx']
        img_path = os.path.join(DATA_DIR, cls, f"{row['image_id']}.jpg")
        img = load_img(img_path, target_size=IMG_SIZE)
        img_array = img_to_array(img) / 255.0
        images.append(img_array)
        ages.append(row['age'])
        sexes.append(row['sex'])
        locs.append(row['localization'])
        labels.append(row['label'])
    return (
        np.array(images),
        np.array(ages).reshape(-1, 1),
        np.array(sexes).reshape(-1, 1),
        np.array(locs),
        tf.keras.utils.to_categorical(np.array(labels), num_classes=len(class_names))
    )

images, ages, sexes, locs, labels = load_data(df)

# Train/val split
X_train, X_val, age_train, age_val, sex_train, sex_val, loc_train, loc_val, y_train, y_val = train_test_split(
    images, ages, sexes, locs, labels, test_size=0.2, stratify=labels.argmax(axis=1), random_state=42
)

# Build model
img_input = layers.Input(shape=IMG_SIZE + (3,))
age_input = layers.Input(shape=(1,))
sex_input = layers.Input(shape=(1,))
loc_input = layers.Input(shape=(locs.shape[1],))

base = EfficientNetV2B0(include_top=False, weights='imagenet', input_tensor=img_input)
x = layers.GlobalAveragePooling2D()(base.output)

meta = layers.Concatenate()([age_input, sex_input, loc_input])
meta = layers.Dense(32, activation='relu')(meta)

combined = layers.Concatenate()([x, meta])
combined = layers.Dense(64, activation='relu')(combined)
combined = layers.Dropout(0.5)(combined)
output = layers.Dense(len(class_names), activation='softmax')(combined)

model = Model(inputs=[img_input, age_input, sex_input, loc_input], outputs=output)

# Compile and train
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

model.fit(
    [X_train, age_train, sex_train, loc_train], y_train,
    validation_data=([X_val, age_val, sex_val, loc_val], y_val),
    epochs=EPOCHS,
    batch_size=BATCH_SIZE
)

# Save model
model.export('multiclass_skin_classifier')

import shutil

shutil.make_archive('multiclass_skin_classifier', 'zip', 'multiclass_skin_classifier')

